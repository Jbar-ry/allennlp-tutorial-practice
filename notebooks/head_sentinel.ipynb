{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## debug some parser stuff\n",
    "#https://github.com/allenai/allennlp/pull/1544/commits/e7d3713194b285d7fde19deccd5375677a06b95d\n",
    "# head sentinel is a random vector that you attach to the start of the sentence -- avoids having to do things like adding dummy root node to all inputs, e.g. [root] + tokens\n",
    "# [root] + pos\n",
    "# e.g. adding dummy root tokens into everything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len = 10\n",
    "dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10])\n",
      "Parameter containing:\n",
      "tensor([[[-0.3128,  0.8670, -0.7462,  0.1871, -0.5698, -0.1392,  0.2054,\n",
      "           0.9493, -1.0815,  0.3115]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "head_sentinel = torch.nn.Parameter(torch.randn([1, 1, dim]))\n",
    "print(head_sentinel.shape)\n",
    "print(head_sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10])\n",
      "tensor([[[-0.0947,  0.1922,  1.1096,  0.0598,  0.6625,  1.1269,  0.9848,\n",
      "           0.3025, -0.1626, -0.7083]]], grad_fn=<ExpandBackward>)\n"
     ]
    }
   ],
   "source": [
    "# head_sentinel: (batch, 1, hidden_dim * 2)\n",
    "head_sentinel = x.expand(1, 1, 10)\n",
    "print(head_sentinel.shape)\n",
    "print(head_sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 10])\n",
      "tensor([[[-9.6737e-01,  7.2086e-01, -9.8140e-01, -2.0691e+00,  3.2324e-01,\n",
      "          -2.8798e-01,  9.7985e-01,  2.2759e-01,  8.6093e-01, -5.2002e-01],\n",
      "         [ 2.5157e-02,  4.1099e-01, -3.4186e-01, -1.5887e+00,  7.4706e-01,\n",
      "          -5.0874e-01, -2.0922e+00, -3.0475e-01,  1.2960e+00,  1.3063e+00],\n",
      "         [-2.1481e-01, -4.2873e-01, -1.2328e+00,  8.1656e-01, -4.8023e-01,\n",
      "          -4.7914e-01, -2.1925e-01,  1.5066e-01, -1.0041e+00, -1.9839e-01],\n",
      "         [ 2.1849e+00, -1.8040e-01,  1.5261e-01,  4.8069e-01,  7.1790e-01,\n",
      "           9.0408e-01, -1.2656e+00,  1.5773e+00, -1.0600e-01, -9.9923e-01],\n",
      "         [-8.9860e-01,  2.5348e-01, -9.0696e-01,  6.0079e-01, -1.0658e+00,\n",
      "          -7.6177e-01, -1.3353e+00, -4.3056e-02, -5.4334e-01,  1.7369e+00],\n",
      "         [-8.8177e-01, -6.6179e-02,  1.9930e+00, -2.7323e+00,  9.0598e-01,\n",
      "           9.5027e-02, -1.0333e+00, -1.5909e-01, -4.8424e-01, -5.6134e-02],\n",
      "         [ 1.9670e-01,  6.4806e-01,  1.1023e-01,  5.7225e-01,  7.4889e-01,\n",
      "          -6.9835e-01, -1.0626e+00, -2.7519e+00,  1.2325e+00, -1.0546e-01],\n",
      "         [ 1.0409e+00, -9.9619e-01,  8.8720e-01,  9.7109e-01,  2.7676e-01,\n",
      "          -1.8032e-02,  2.1581e+00,  1.5230e-01,  1.8607e+00,  7.4872e-02],\n",
      "         [-2.2386e-01, -4.9113e-01,  4.3501e-02, -7.5787e-02, -9.5794e-01,\n",
      "          -9.2994e-01, -8.4630e-02,  4.5205e-01, -1.3301e+00, -1.6415e+00],\n",
      "         [-8.1328e-01,  1.2390e-01,  2.9745e-02, -3.5872e-02,  1.8396e-01,\n",
      "          -1.4216e+00, -8.3284e-01, -2.0702e+00,  1.2112e-02, -6.1925e-01]],\n",
      "\n",
      "        [[-2.2200e-01, -4.2211e-01,  1.6330e-01,  1.4621e+00, -5.2857e-01,\n",
      "          -1.0596e+00, -9.4671e-01,  1.1378e+00, -1.0933e+00,  2.1981e+00],\n",
      "         [ 1.4330e+00,  8.1244e-01,  2.0712e+00, -5.6213e-01, -1.4160e+00,\n",
      "          -6.6203e-01,  2.5640e-01,  4.7322e-02, -5.9357e-01, -4.5758e-01],\n",
      "         [-2.2349e+00,  1.6277e+00,  9.5528e-01,  5.0478e-01, -1.2134e+00,\n",
      "           7.5803e-01, -3.2384e-01,  5.1302e-01,  2.4977e+00, -1.5820e-01],\n",
      "         [ 1.3546e+00,  1.5144e-01, -4.5704e-02,  3.5397e-01,  1.0145e+00,\n",
      "           3.3250e-01,  1.8220e+00, -1.0220e+00,  1.1462e+00,  2.8952e+00],\n",
      "         [ 8.9695e-01, -2.8947e-01, -3.0246e-01, -2.5391e-01, -1.8963e-01,\n",
      "          -7.6833e-01, -8.6619e-01,  1.1980e+00, -1.3708e+00, -3.1439e-01],\n",
      "         [ 5.7615e-02, -1.8867e+00,  5.9413e-01, -9.9624e-01,  9.9299e-01,\n",
      "          -5.9391e-01,  2.2760e+00,  7.3144e-02,  6.6806e-01, -2.4009e-02],\n",
      "         [-2.5711e-01,  1.8053e+00,  2.3404e+00, -4.1397e-01, -1.7219e+00,\n",
      "           1.0250e+00, -4.9964e-01,  1.3059e+00, -5.0967e-01,  4.8662e-02],\n",
      "         [-1.2329e+00,  9.7232e-01,  1.4069e+00, -1.5614e+00,  1.2937e-01,\n",
      "          -1.2250e+00,  3.0263e-02, -2.9501e-01, -1.0823e-01,  1.3054e+00],\n",
      "         [-2.7153e+00,  4.9121e-01, -2.7059e-01,  8.2819e-01, -1.0717e+00,\n",
      "          -5.8337e-01,  1.5681e-01, -4.9132e-01,  6.0534e-01, -1.5285e+00],\n",
      "         [-6.3597e-02,  5.5296e-01, -1.7007e+00, -1.3899e-01, -9.9691e-01,\n",
      "           9.1003e-01,  2.6012e-01,  2.9679e-01,  6.1557e-01,  6.7410e-01]],\n",
      "\n",
      "        [[-1.1440e+00,  2.8770e+00, -1.4039e-02,  2.3977e-01, -1.0662e+00,\n",
      "           5.4558e-01, -5.7741e-01, -1.0626e+00,  1.7576e-01, -8.7576e-01],\n",
      "         [-3.2365e-02,  2.9089e-01, -4.4016e-03,  1.0097e-01,  1.0181e+00,\n",
      "           1.4601e+00,  2.7860e-01, -6.2803e-01,  7.0968e-01, -6.2821e-03],\n",
      "         [ 3.6003e-01, -7.8110e-01,  6.7473e-01, -2.5815e-01, -1.7440e+00,\n",
      "          -3.8462e-04,  1.0921e+00, -6.2484e-01,  3.4864e-01, -3.1190e-01],\n",
      "         [-1.3577e+00,  7.0917e-01,  3.9670e-01,  4.2418e-01, -6.8688e-01,\n",
      "           6.0709e-01, -4.3074e-01,  3.5980e-01,  3.4806e-02,  8.7476e-01],\n",
      "         [-6.7763e-01,  1.8674e-01, -1.7386e+00, -1.2178e-01,  2.2323e-01,\n",
      "          -1.4858e+00,  9.4435e-01,  5.7754e-02,  6.4289e-01, -2.9042e-01],\n",
      "         [-2.3194e-01, -1.4853e+00, -1.4577e+00,  1.1802e+00,  1.6946e-01,\n",
      "           1.0271e-01,  2.7426e+00, -5.5010e-01, -3.4981e-01, -2.0867e+00],\n",
      "         [ 2.6963e-01, -7.7048e-01, -8.5602e-01, -1.0142e+00, -1.0178e+00,\n",
      "           1.0881e+00, -6.2868e-01, -7.1800e-01, -1.0129e+00, -3.2185e-01],\n",
      "         [-2.7319e-01, -7.8287e-01,  4.4807e-01,  8.3667e-01, -1.8791e+00,\n",
      "           9.0864e-01, -4.0831e-01,  1.8428e-01,  6.8041e-01, -1.9448e+00],\n",
      "         [ 2.8931e-01,  1.1293e+00,  4.0394e-01,  8.9412e-01, -1.1891e+00,\n",
      "           2.2818e+00, -1.0972e+00, -4.1238e-01, -1.9583e-01, -1.9222e-01],\n",
      "         [ 5.9371e-01, -1.8840e-01,  6.3859e-02,  7.6624e-01,  3.7421e-02,\n",
      "          -4.9112e-01, -1.0116e+00, -4.5789e-01, -1.4486e+00,  3.2987e-02]],\n",
      "\n",
      "        [[-6.4704e-01,  9.8564e-02,  4.2346e-01, -3.2204e-01,  2.8973e-01,\n",
      "           4.9243e-01,  1.3223e+00, -5.1923e-01, -1.0294e+00, -2.1044e-01],\n",
      "         [ 1.0638e+00,  3.2314e-01, -4.8362e-01,  2.8328e+00, -1.2422e+00,\n",
      "          -3.2318e-01,  3.3158e-01,  6.8467e-05, -9.6564e-02, -2.6004e-02],\n",
      "         [-7.0814e-01,  1.7723e-01,  7.6033e-01, -1.3450e+00,  4.8862e-01,\n",
      "           4.1475e-01,  7.5361e-01,  4.2040e-01, -2.3621e-01,  7.3974e-01],\n",
      "         [-9.8339e-01, -1.7694e+00, -1.2456e+00, -4.2152e-01, -6.8230e-01,\n",
      "           1.0280e+00, -1.2264e+00,  2.3687e-02, -3.2743e-01, -3.0243e-01],\n",
      "         [-1.0163e+00,  7.0879e-01,  4.6470e-01,  2.8766e-01, -3.8088e-01,\n",
      "          -1.4479e+00,  1.4272e+00,  1.2646e+00,  1.7156e-01, -5.5923e-01],\n",
      "         [ 2.1828e-01, -6.0946e-01,  2.0377e+00,  1.1200e+00,  4.4786e-01,\n",
      "           9.5956e-01, -1.4519e+00,  1.0712e+00, -1.3164e+00,  4.4952e-01],\n",
      "         [ 4.3357e-01,  9.1672e-01, -8.9398e-01,  1.3433e+00, -3.6855e-01,\n",
      "           1.9338e+00, -3.1857e-01, -7.1616e-01, -1.0372e-01,  1.5108e+00],\n",
      "         [-1.3482e+00,  2.0646e-01, -3.5826e-01, -2.7133e-01,  7.1808e-01,\n",
      "          -1.7413e-01, -5.6826e-01,  6.8207e-01,  1.2618e+00,  1.0337e+00],\n",
      "         [ 5.7565e-02,  1.4791e+00,  6.3959e-01,  3.2133e-01, -1.7053e+00,\n",
      "           8.6011e-01, -5.8869e-02, -1.4242e+00,  3.1836e-01, -5.9573e-01],\n",
      "         [ 6.8357e-01,  1.1250e+00, -6.8277e-01, -9.5599e-01,  7.6930e-03,\n",
      "          -5.9277e-01, -8.3670e-02, -5.9354e-02, -1.8383e-01, -3.9956e-02]]])\n"
     ]
    }
   ],
   "source": [
    "encoded_text = torch.randn(batch_size, seq_len, dim)\n",
    "print(encoded_text.shape)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 10])\n",
      "tensor([[[-0.3128,  0.8670, -0.7462,  0.1871, -0.5698, -0.1392,  0.2054,\n",
      "           0.9493, -1.0815,  0.3115]],\n",
      "\n",
      "        [[-0.3128,  0.8670, -0.7462,  0.1871, -0.5698, -0.1392,  0.2054,\n",
      "           0.9493, -1.0815,  0.3115]],\n",
      "\n",
      "        [[-0.3128,  0.8670, -0.7462,  0.1871, -0.5698, -0.1392,  0.2054,\n",
      "           0.9493, -1.0815,  0.3115]],\n",
      "\n",
      "        [[-0.3128,  0.8670, -0.7462,  0.1871, -0.5698, -0.1392,  0.2054,\n",
      "           0.9493, -1.0815,  0.3115]]], grad_fn=<ExpandBackward>)\n"
     ]
    }
   ],
   "source": [
    "# expand the random vector to batch size\n",
    "head_sentinel = head_sentinel.expand(batch_size, 1, dim)\n",
    "print(head_sentinel.shape)\n",
    "print(head_sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11, 10])\n",
      "tensor([[[-3.1280e-01,  8.6699e-01, -7.4618e-01,  1.8715e-01, -5.6982e-01,\n",
      "          -1.3918e-01,  2.0538e-01,  9.4934e-01, -1.0815e+00,  3.1146e-01],\n",
      "         [-9.6737e-01,  7.2086e-01, -9.8140e-01, -2.0691e+00,  3.2324e-01,\n",
      "          -2.8798e-01,  9.7985e-01,  2.2759e-01,  8.6093e-01, -5.2002e-01],\n",
      "         [ 2.5157e-02,  4.1099e-01, -3.4186e-01, -1.5887e+00,  7.4706e-01,\n",
      "          -5.0874e-01, -2.0922e+00, -3.0475e-01,  1.2960e+00,  1.3063e+00],\n",
      "         [-2.1481e-01, -4.2873e-01, -1.2328e+00,  8.1656e-01, -4.8023e-01,\n",
      "          -4.7914e-01, -2.1925e-01,  1.5066e-01, -1.0041e+00, -1.9839e-01],\n",
      "         [ 2.1849e+00, -1.8040e-01,  1.5261e-01,  4.8069e-01,  7.1790e-01,\n",
      "           9.0408e-01, -1.2656e+00,  1.5773e+00, -1.0600e-01, -9.9923e-01],\n",
      "         [-8.9860e-01,  2.5348e-01, -9.0696e-01,  6.0079e-01, -1.0658e+00,\n",
      "          -7.6177e-01, -1.3353e+00, -4.3056e-02, -5.4334e-01,  1.7369e+00],\n",
      "         [-8.8177e-01, -6.6179e-02,  1.9930e+00, -2.7323e+00,  9.0598e-01,\n",
      "           9.5027e-02, -1.0333e+00, -1.5909e-01, -4.8424e-01, -5.6134e-02],\n",
      "         [ 1.9670e-01,  6.4806e-01,  1.1023e-01,  5.7225e-01,  7.4889e-01,\n",
      "          -6.9835e-01, -1.0626e+00, -2.7519e+00,  1.2325e+00, -1.0546e-01],\n",
      "         [ 1.0409e+00, -9.9619e-01,  8.8720e-01,  9.7109e-01,  2.7676e-01,\n",
      "          -1.8032e-02,  2.1581e+00,  1.5230e-01,  1.8607e+00,  7.4872e-02],\n",
      "         [-2.2386e-01, -4.9113e-01,  4.3501e-02, -7.5787e-02, -9.5794e-01,\n",
      "          -9.2994e-01, -8.4630e-02,  4.5205e-01, -1.3301e+00, -1.6415e+00],\n",
      "         [-8.1328e-01,  1.2390e-01,  2.9745e-02, -3.5872e-02,  1.8396e-01,\n",
      "          -1.4216e+00, -8.3284e-01, -2.0702e+00,  1.2112e-02, -6.1925e-01]],\n",
      "\n",
      "        [[-3.1280e-01,  8.6699e-01, -7.4618e-01,  1.8715e-01, -5.6982e-01,\n",
      "          -1.3918e-01,  2.0538e-01,  9.4934e-01, -1.0815e+00,  3.1146e-01],\n",
      "         [-2.2200e-01, -4.2211e-01,  1.6330e-01,  1.4621e+00, -5.2857e-01,\n",
      "          -1.0596e+00, -9.4671e-01,  1.1378e+00, -1.0933e+00,  2.1981e+00],\n",
      "         [ 1.4330e+00,  8.1244e-01,  2.0712e+00, -5.6213e-01, -1.4160e+00,\n",
      "          -6.6203e-01,  2.5640e-01,  4.7322e-02, -5.9357e-01, -4.5758e-01],\n",
      "         [-2.2349e+00,  1.6277e+00,  9.5528e-01,  5.0478e-01, -1.2134e+00,\n",
      "           7.5803e-01, -3.2384e-01,  5.1302e-01,  2.4977e+00, -1.5820e-01],\n",
      "         [ 1.3546e+00,  1.5144e-01, -4.5704e-02,  3.5397e-01,  1.0145e+00,\n",
      "           3.3250e-01,  1.8220e+00, -1.0220e+00,  1.1462e+00,  2.8952e+00],\n",
      "         [ 8.9695e-01, -2.8947e-01, -3.0246e-01, -2.5391e-01, -1.8963e-01,\n",
      "          -7.6833e-01, -8.6619e-01,  1.1980e+00, -1.3708e+00, -3.1439e-01],\n",
      "         [ 5.7615e-02, -1.8867e+00,  5.9413e-01, -9.9624e-01,  9.9299e-01,\n",
      "          -5.9391e-01,  2.2760e+00,  7.3144e-02,  6.6806e-01, -2.4009e-02],\n",
      "         [-2.5711e-01,  1.8053e+00,  2.3404e+00, -4.1397e-01, -1.7219e+00,\n",
      "           1.0250e+00, -4.9964e-01,  1.3059e+00, -5.0967e-01,  4.8662e-02],\n",
      "         [-1.2329e+00,  9.7232e-01,  1.4069e+00, -1.5614e+00,  1.2937e-01,\n",
      "          -1.2250e+00,  3.0263e-02, -2.9501e-01, -1.0823e-01,  1.3054e+00],\n",
      "         [-2.7153e+00,  4.9121e-01, -2.7059e-01,  8.2819e-01, -1.0717e+00,\n",
      "          -5.8337e-01,  1.5681e-01, -4.9132e-01,  6.0534e-01, -1.5285e+00],\n",
      "         [-6.3597e-02,  5.5296e-01, -1.7007e+00, -1.3899e-01, -9.9691e-01,\n",
      "           9.1003e-01,  2.6012e-01,  2.9679e-01,  6.1557e-01,  6.7410e-01]],\n",
      "\n",
      "        [[-3.1280e-01,  8.6699e-01, -7.4618e-01,  1.8715e-01, -5.6982e-01,\n",
      "          -1.3918e-01,  2.0538e-01,  9.4934e-01, -1.0815e+00,  3.1146e-01],\n",
      "         [-1.1440e+00,  2.8770e+00, -1.4039e-02,  2.3977e-01, -1.0662e+00,\n",
      "           5.4558e-01, -5.7741e-01, -1.0626e+00,  1.7576e-01, -8.7576e-01],\n",
      "         [-3.2365e-02,  2.9089e-01, -4.4016e-03,  1.0097e-01,  1.0181e+00,\n",
      "           1.4601e+00,  2.7860e-01, -6.2803e-01,  7.0968e-01, -6.2821e-03],\n",
      "         [ 3.6003e-01, -7.8110e-01,  6.7473e-01, -2.5815e-01, -1.7440e+00,\n",
      "          -3.8462e-04,  1.0921e+00, -6.2484e-01,  3.4864e-01, -3.1190e-01],\n",
      "         [-1.3577e+00,  7.0917e-01,  3.9670e-01,  4.2418e-01, -6.8688e-01,\n",
      "           6.0709e-01, -4.3074e-01,  3.5980e-01,  3.4806e-02,  8.7476e-01],\n",
      "         [-6.7763e-01,  1.8674e-01, -1.7386e+00, -1.2178e-01,  2.2323e-01,\n",
      "          -1.4858e+00,  9.4435e-01,  5.7754e-02,  6.4289e-01, -2.9042e-01],\n",
      "         [-2.3194e-01, -1.4853e+00, -1.4577e+00,  1.1802e+00,  1.6946e-01,\n",
      "           1.0271e-01,  2.7426e+00, -5.5010e-01, -3.4981e-01, -2.0867e+00],\n",
      "         [ 2.6963e-01, -7.7048e-01, -8.5602e-01, -1.0142e+00, -1.0178e+00,\n",
      "           1.0881e+00, -6.2868e-01, -7.1800e-01, -1.0129e+00, -3.2185e-01],\n",
      "         [-2.7319e-01, -7.8287e-01,  4.4807e-01,  8.3667e-01, -1.8791e+00,\n",
      "           9.0864e-01, -4.0831e-01,  1.8428e-01,  6.8041e-01, -1.9448e+00],\n",
      "         [ 2.8931e-01,  1.1293e+00,  4.0394e-01,  8.9412e-01, -1.1891e+00,\n",
      "           2.2818e+00, -1.0972e+00, -4.1238e-01, -1.9583e-01, -1.9222e-01],\n",
      "         [ 5.9371e-01, -1.8840e-01,  6.3859e-02,  7.6624e-01,  3.7421e-02,\n",
      "          -4.9112e-01, -1.0116e+00, -4.5789e-01, -1.4486e+00,  3.2987e-02]],\n",
      "\n",
      "        [[-3.1280e-01,  8.6699e-01, -7.4618e-01,  1.8715e-01, -5.6982e-01,\n",
      "          -1.3918e-01,  2.0538e-01,  9.4934e-01, -1.0815e+00,  3.1146e-01],\n",
      "         [-6.4704e-01,  9.8564e-02,  4.2346e-01, -3.2204e-01,  2.8973e-01,\n",
      "           4.9243e-01,  1.3223e+00, -5.1923e-01, -1.0294e+00, -2.1044e-01],\n",
      "         [ 1.0638e+00,  3.2314e-01, -4.8362e-01,  2.8328e+00, -1.2422e+00,\n",
      "          -3.2318e-01,  3.3158e-01,  6.8467e-05, -9.6564e-02, -2.6004e-02],\n",
      "         [-7.0814e-01,  1.7723e-01,  7.6033e-01, -1.3450e+00,  4.8862e-01,\n",
      "           4.1475e-01,  7.5361e-01,  4.2040e-01, -2.3621e-01,  7.3974e-01],\n",
      "         [-9.8339e-01, -1.7694e+00, -1.2456e+00, -4.2152e-01, -6.8230e-01,\n",
      "           1.0280e+00, -1.2264e+00,  2.3687e-02, -3.2743e-01, -3.0243e-01],\n",
      "         [-1.0163e+00,  7.0879e-01,  4.6470e-01,  2.8766e-01, -3.8088e-01,\n",
      "          -1.4479e+00,  1.4272e+00,  1.2646e+00,  1.7156e-01, -5.5923e-01],\n",
      "         [ 2.1828e-01, -6.0946e-01,  2.0377e+00,  1.1200e+00,  4.4786e-01,\n",
      "           9.5956e-01, -1.4519e+00,  1.0712e+00, -1.3164e+00,  4.4952e-01],\n",
      "         [ 4.3357e-01,  9.1672e-01, -8.9398e-01,  1.3433e+00, -3.6855e-01,\n",
      "           1.9338e+00, -3.1857e-01, -7.1616e-01, -1.0372e-01,  1.5108e+00],\n",
      "         [-1.3482e+00,  2.0646e-01, -3.5826e-01, -2.7133e-01,  7.1808e-01,\n",
      "          -1.7413e-01, -5.6826e-01,  6.8207e-01,  1.2618e+00,  1.0337e+00],\n",
      "         [ 5.7565e-02,  1.4791e+00,  6.3959e-01,  3.2133e-01, -1.7053e+00,\n",
      "           8.6011e-01, -5.8869e-02, -1.4242e+00,  3.1836e-01, -5.9573e-01],\n",
      "         [ 6.8357e-01,  1.1250e+00, -6.8277e-01, -9.5599e-01,  7.6930e-03,\n",
      "          -5.9277e-01, -8.3670e-02, -5.9354e-02, -1.8383e-01, -3.9956e-02]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the head sentinel onto the sentence representation.\n",
    "encoded_text = torch.cat([head_sentinel, encoded_text], 1)\n",
    "print(encoded_text.shape)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "torch.Size([4, 10])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.ones(batch_size, seq_len)\n",
    "print(mask.shape)\n",
    "print(mask)\n",
    "# just pad the last element\n",
    "mask[(0,-1)] = 0\n",
    "mask[(1,-1)] = 0\n",
    "mask[(2,-1)] = 0\n",
    "mask[(3,-1)] = 0\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.cat([mask.new_ones(batch_size, 1), mask], 1)\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n",
      "tensor([[5, 1, 3, 0, 0, 1, 4, 2, 3, 0],\n",
      "        [5, 7, 8, 2, 0, 6, 0, 6, 9, 3],\n",
      "        [9, 9, 3, 0, 9, 8, 2, 4, 8, 9],\n",
      "        [5, 3, 2, 9, 8, 6, 0, 3, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "head_indices = torch.LongTensor(batch_size, seq_len).random_(0, 10)\n",
    "print(head_indices.shape)\n",
    "print(head_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11])\n",
      "tensor([[0, 5, 1, 3, 0, 0, 1, 4, 2, 3, 0],\n",
      "        [0, 5, 7, 8, 2, 0, 6, 0, 6, 9, 3],\n",
      "        [0, 9, 9, 3, 0, 9, 8, 2, 4, 8, 9],\n",
      "        [0, 5, 3, 2, 9, 8, 6, 0, 3, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "head_indices = torch.cat([head_indices.new_zeros(batch_size, 1), head_indices], 1)\n",
    "print(head_indices.shape)\n",
    "print(head_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11])\n",
      "tensor([[        -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "                 -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "         -100000000.],\n",
      "        [        -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "                 -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "         -100000000.],\n",
      "        [        -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "                 -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "         -100000000.],\n",
      "        [        -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "                 -0.,         -0.,         -0.,         -0.,         -0.,\n",
      "         -100000000.]])\n"
     ]
    }
   ],
   "source": [
    "float_mask = mask.float()\n",
    "minus_inf = -1e8\n",
    "# -.0 where ones are usually otherwise the 1 is multiplid by -inf\n",
    "minus_mask = (1 - float_mask) * minus_inf\n",
    "# add minus mask to attended arcs (mask out values we don't want?)\n",
    "print(minus_mask.shape)\n",
    "print(minus_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11, 11])\n",
      "tensor([[[-9.8183e-01,  1.1594e+00, -2.0109e+00,  5.6744e-01, -3.8066e-02,\n",
      "           7.0324e-01, -1.7452e+00, -8.7935e-02,  2.4882e-01,  8.6160e-01,\n",
      "           5.2000e-01],\n",
      "         [-5.9327e-01, -1.3349e+00, -9.4245e-01, -3.8243e-01, -3.6044e-01,\n",
      "           1.8792e+00, -2.3008e+00, -1.8833e-01, -1.5625e+00, -1.0101e+00,\n",
      "          -6.0017e-01],\n",
      "         [ 5.8026e-02,  1.5312e+00, -3.3651e-01,  8.5580e-01,  5.4043e-02,\n",
      "          -8.2895e-01,  8.9131e-01,  4.5121e-01,  2.0602e+00,  3.5775e-01,\n",
      "           6.2936e-01],\n",
      "         [-8.6685e-01, -3.3771e-01, -6.0243e-01, -1.5533e+00, -2.9116e-01,\n",
      "           1.2682e+00, -2.3876e-01, -5.0341e-01, -3.1285e-02, -7.2232e-01,\n",
      "           5.9311e-02],\n",
      "         [-3.0391e-01,  7.9372e-01,  7.3996e-01,  1.5863e+00, -1.5021e+00,\n",
      "          -7.4746e-01,  6.3929e-01, -7.1581e-02,  7.0488e-01, -4.0408e-01,\n",
      "          -1.1169e+00],\n",
      "         [-6.8853e-01,  9.1334e-01,  2.5664e-01, -1.0112e-01, -2.7055e+00,\n",
      "           1.2839e+00,  9.6319e-01, -1.0829e+00, -3.8901e-01,  5.7087e-01,\n",
      "          -9.5006e-02],\n",
      "         [ 6.7102e-01,  1.0842e+00, -1.2292e+00,  7.9358e-01, -2.7061e-01,\n",
      "           1.4037e+00,  8.9309e-02, -7.6738e-01,  4.1541e-01,  9.6414e-01,\n",
      "          -1.0550e+00],\n",
      "         [-1.0348e+00,  4.0087e-02,  3.0258e-01, -1.1417e+00,  5.8291e-01,\n",
      "           9.8395e-01, -2.6026e-01, -3.2715e-01, -3.4050e-01, -4.3353e-01,\n",
      "           1.0141e+00],\n",
      "         [ 5.1357e-01,  9.2952e-02,  4.4281e-01,  6.8645e-01,  3.5492e-01,\n",
      "           3.0857e-01, -3.3487e-01, -8.3809e-01,  6.4943e-01,  2.9010e-01,\n",
      "          -3.1343e-01],\n",
      "         [ 2.8900e-01,  5.7676e-01, -1.6713e+00,  4.5942e-01,  1.0313e+00,\n",
      "           6.2975e-01,  3.5775e-01,  2.8952e-01, -3.4040e-01,  2.0904e+00,\n",
      "          -6.2106e-01],\n",
      "         [ 1.1196e-02, -6.2786e-01,  4.9676e-01,  5.4969e-01,  9.6461e-01,\n",
      "           6.7784e-01,  6.8479e-01,  2.5217e+00,  1.2786e-01,  9.8349e-01,\n",
      "           1.7442e-01]],\n",
      "\n",
      "        [[ 1.0871e-01,  2.7952e-01,  1.7635e+00,  5.6416e-01,  5.8431e-03,\n",
      "           1.2305e+00, -6.1433e-01, -6.2579e-01, -2.0483e-02, -4.6495e-01,\n",
      "          -4.8653e-01],\n",
      "         [-7.8710e-01,  8.6694e-01,  2.7874e-01, -1.4588e+00,  5.4702e-02,\n",
      "          -3.9105e-01,  8.9033e-01,  4.9009e-01,  9.8705e-02,  1.8824e+00,\n",
      "          -5.7631e-01],\n",
      "         [-1.0626e+00,  7.7517e-01,  1.6693e+00, -1.1462e+00, -7.7567e-01,\n",
      "           2.9047e-01,  1.5410e+00,  3.0078e-01, -3.6842e-01,  1.2813e-01,\n",
      "          -2.3509e-01],\n",
      "         [-1.6343e-01, -4.5680e-01, -6.3909e-01, -1.3950e-01,  2.4925e-01,\n",
      "          -2.4321e-03, -5.6720e-01, -8.8464e-01, -6.1672e-01, -1.2580e+00,\n",
      "          -8.0767e-01],\n",
      "         [-1.5102e-01, -2.3638e-01, -1.0401e+00,  7.2062e-01, -1.6347e-01,\n",
      "          -1.4304e+00,  1.7046e+00, -3.5411e-01,  7.2751e-01,  1.0953e+00,\n",
      "          -1.0939e+00],\n",
      "         [-7.3963e-01, -9.3602e-02, -9.2488e-01, -8.0839e-01, -3.2466e-01,\n",
      "           4.8066e-01,  3.4536e-01,  1.5819e-01,  1.0314e+00, -4.2458e-02,\n",
      "          -6.8476e-01],\n",
      "         [ 4.6180e-01,  6.4232e-01, -5.5925e-01, -5.0015e-02,  8.1609e-01,\n",
      "           2.2447e-01,  1.7295e+00,  1.0687e+00,  6.3636e-01, -5.0780e-01,\n",
      "           1.4105e+00],\n",
      "         [-8.1686e-01, -6.4404e-01,  1.4140e+00, -1.8898e+00, -3.4447e-01,\n",
      "           8.9468e-01,  2.1425e-01,  4.4432e-01,  7.6776e-01, -5.3645e-01,\n",
      "           1.1004e+00],\n",
      "         [-9.3217e-01, -1.8497e-02,  1.0658e+00,  3.6539e-01,  1.0118e+00,\n",
      "           7.9211e-01,  1.7114e-01, -1.7501e+00, -6.1379e-01, -7.7250e-01,\n",
      "           1.6370e-01],\n",
      "         [-5.0435e-01,  9.3028e-01,  2.5803e-01,  1.6756e-01,  4.7746e-01,\n",
      "           7.7321e-01, -1.1363e+00, -9.1338e-01, -6.8551e-01,  1.4998e-01,\n",
      "          -1.5206e-01],\n",
      "         [-2.2687e-01,  9.2669e-01, -4.6720e-01, -1.8330e+00,  1.6787e+00,\n",
      "           2.0216e-01,  1.3262e+00,  1.7280e+00,  1.8705e+00, -6.3758e-01,\n",
      "           1.5773e+00]],\n",
      "\n",
      "        [[-4.5537e-01, -1.2566e+00,  1.4479e+00, -1.4813e+00, -1.1770e+00,\n",
      "           1.0420e+00, -2.5060e-01,  1.4924e+00, -1.5341e+00, -5.1038e-01,\n",
      "          -1.6257e-01],\n",
      "         [-2.0571e-02, -1.1269e+00, -5.6797e-01, -3.5509e-01,  9.9108e-01,\n",
      "          -9.2670e-01, -1.5052e-01,  1.5954e+00, -2.4166e-01, -1.1794e+00,\n",
      "          -9.3837e-01],\n",
      "         [-5.3972e-01,  2.1648e+00,  1.0947e+00,  2.0992e-01,  1.0105e+00,\n",
      "           1.9301e-01,  5.2334e-01, -1.4063e-01, -9.1141e-01,  9.2613e-01,\n",
      "          -1.3116e+00],\n",
      "         [ 1.0533e+00, -1.4137e+00,  1.0931e+00,  1.3018e+00,  1.2092e-01,\n",
      "          -2.0862e-01,  4.7123e-01, -1.9379e-01,  1.0685e+00,  1.6533e-01,\n",
      "           1.5532e+00],\n",
      "         [-7.0628e-01, -1.5498e+00, -1.8773e+00,  8.1737e-01, -2.1485e+00,\n",
      "           1.8885e+00, -5.6085e-01, -4.6964e-01, -1.1633e-01,  1.8034e+00,\n",
      "          -1.1944e+00],\n",
      "         [-5.3152e-01,  1.5569e+00, -8.7097e-01,  1.7899e+00, -1.1912e+00,\n",
      "          -7.2379e-01, -6.0369e-01,  1.3037e+00, -7.4123e-01, -7.0488e-01,\n",
      "           1.4101e+00],\n",
      "         [-3.1768e-01,  8.0070e-01,  1.0197e+00, -1.3190e-01, -9.5549e-01,\n",
      "           1.1795e+00, -4.6479e-01, -2.9195e-01, -6.4633e-01, -1.7569e+00,\n",
      "           1.9217e-01],\n",
      "         [-2.6076e-01,  1.1965e-01,  1.5680e+00,  1.6040e-01,  6.4690e-01,\n",
      "           7.2718e-01, -1.1476e+00,  6.6797e-01,  2.3430e-03, -5.4070e-01,\n",
      "          -1.6911e-01],\n",
      "         [ 1.1671e+00, -3.9987e-01, -1.9008e-01,  1.6973e+00,  9.7039e-01,\n",
      "           5.6149e-01, -4.7124e-01,  1.2055e+00,  1.1968e+00,  1.5100e+00,\n",
      "           9.9632e-02],\n",
      "         [ 1.8685e+00,  4.9056e-01, -1.3559e+00, -1.3839e-01, -1.3964e+00,\n",
      "          -5.4609e-01, -9.8165e-01,  5.6158e-01, -1.9001e+00, -1.1090e+00,\n",
      "           3.4420e-03],\n",
      "         [ 8.6380e-01, -1.7862e-01, -6.9135e-01, -9.7771e-01,  7.7819e-01,\n",
      "           1.2526e-01, -5.9009e-01, -1.7615e+00,  8.1819e-01, -1.5915e-01,\n",
      "          -7.4812e-01]],\n",
      "\n",
      "        [[-1.0950e+00, -3.0762e+00,  9.1229e-01,  3.8455e-01,  2.5701e-01,\n",
      "           7.9110e-01,  5.7016e-01,  8.1079e-01, -1.3280e-02,  8.8295e-01,\n",
      "          -5.1830e-01],\n",
      "         [ 1.9105e-01, -5.3701e-01,  1.5074e+00, -8.8040e-01,  2.7199e-02,\n",
      "           1.4682e+00,  7.3866e-01,  1.2402e+00,  5.2677e-02,  2.4508e-01,\n",
      "           3.3148e-01],\n",
      "         [-8.2665e-01,  8.1436e-01, -1.5395e+00,  5.4539e-01,  9.9772e-01,\n",
      "          -2.9221e-01,  6.5085e-02, -1.4083e+00,  8.7026e-01, -1.1413e+00,\n",
      "           5.7060e-01],\n",
      "         [-8.4143e-01,  5.4913e-01, -5.8607e-02,  2.6967e-01,  8.4681e-02,\n",
      "           3.1634e-01, -1.3765e-01,  1.2593e+00, -3.6043e-01,  1.5472e-01,\n",
      "           6.0890e-01],\n",
      "         [ 8.9309e-01, -5.0531e-01,  8.6123e-01,  6.1226e-01,  6.0120e-01,\n",
      "          -5.9298e-01, -1.0930e+00, -9.1665e-01,  1.4710e+00,  1.4639e-01,\n",
      "          -1.7265e-01],\n",
      "         [ 4.0225e-01, -1.6845e-01,  6.7015e-02,  1.5354e+00,  6.8751e-02,\n",
      "           9.5957e-01,  4.6851e-02, -9.0268e-01, -5.3035e-01,  1.4555e+00,\n",
      "           1.5544e+00],\n",
      "         [ 1.6444e-01,  8.9052e-01,  7.6449e-01, -7.8986e-01, -6.0202e-02,\n",
      "          -1.1368e+00, -4.1138e-01,  6.8850e-01,  4.4923e-01, -4.9841e-02,\n",
      "           1.8477e+00],\n",
      "         [-5.2292e-01,  4.2523e-01,  5.1964e-01, -4.8753e-01,  5.3084e-01,\n",
      "           1.9917e+00, -2.5837e-01, -3.4599e-01,  4.5572e-01, -3.8770e-01,\n",
      "          -1.9529e+00],\n",
      "         [ 1.0253e-01,  1.7645e+00, -1.0996e+00, -7.3824e-01, -1.7931e-01,\n",
      "           1.2732e-01, -8.9078e-03, -2.1203e+00, -6.7686e-01, -1.8467e+00,\n",
      "          -2.0590e+00],\n",
      "         [-1.2552e-01, -5.4513e-01, -7.4059e-01, -2.4909e-01,  1.4196e+00,\n",
      "           1.0743e+00,  2.2181e+00,  4.2201e-01, -1.1918e+00, -3.9275e-01,\n",
      "          -2.5930e-01],\n",
      "         [-8.8598e-01, -2.4581e-01, -7.8489e-02,  7.4731e-01, -1.3552e+00,\n",
      "           1.8528e+00, -1.3302e+00,  4.5244e-01, -1.1760e+00,  2.5795e-01,\n",
      "           1.3600e+00]]])\n"
     ]
    }
   ],
   "source": [
    "attended_arcs = torch.randn(batch_size, seq_len+1, seq_len+1)\n",
    "print(attended_arcs.shape)\n",
    "print(attended_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11, 11])\n",
      "tensor([[[-9.8183e-01,  1.1594e+00, -2.0109e+00,  5.6744e-01, -3.8066e-02,\n",
      "           7.0324e-01, -1.7452e+00, -8.7935e-02,  2.4882e-01,  8.6160e-01,\n",
      "          -1.0000e+08],\n",
      "         [-5.9327e-01, -1.3349e+00, -9.4245e-01, -3.8243e-01, -3.6044e-01,\n",
      "           1.8792e+00, -2.3008e+00, -1.8833e-01, -1.5625e+00, -1.0101e+00,\n",
      "          -1.0000e+08],\n",
      "         [ 5.8026e-02,  1.5312e+00, -3.3651e-01,  8.5580e-01,  5.4043e-02,\n",
      "          -8.2895e-01,  8.9131e-01,  4.5121e-01,  2.0602e+00,  3.5775e-01,\n",
      "          -1.0000e+08],\n",
      "         [-8.6685e-01, -3.3771e-01, -6.0243e-01, -1.5533e+00, -2.9116e-01,\n",
      "           1.2682e+00, -2.3876e-01, -5.0341e-01, -3.1285e-02, -7.2232e-01,\n",
      "          -1.0000e+08],\n",
      "         [-3.0391e-01,  7.9372e-01,  7.3996e-01,  1.5863e+00, -1.5021e+00,\n",
      "          -7.4746e-01,  6.3929e-01, -7.1581e-02,  7.0488e-01, -4.0408e-01,\n",
      "          -1.0000e+08],\n",
      "         [-6.8853e-01,  9.1334e-01,  2.5664e-01, -1.0112e-01, -2.7055e+00,\n",
      "           1.2839e+00,  9.6319e-01, -1.0829e+00, -3.8901e-01,  5.7087e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 6.7102e-01,  1.0842e+00, -1.2292e+00,  7.9358e-01, -2.7061e-01,\n",
      "           1.4037e+00,  8.9309e-02, -7.6738e-01,  4.1541e-01,  9.6414e-01,\n",
      "          -1.0000e+08],\n",
      "         [-1.0348e+00,  4.0087e-02,  3.0258e-01, -1.1417e+00,  5.8291e-01,\n",
      "           9.8395e-01, -2.6026e-01, -3.2715e-01, -3.4050e-01, -4.3353e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 5.1357e-01,  9.2952e-02,  4.4281e-01,  6.8645e-01,  3.5492e-01,\n",
      "           3.0857e-01, -3.3487e-01, -8.3809e-01,  6.4943e-01,  2.9010e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 2.8900e-01,  5.7676e-01, -1.6713e+00,  4.5942e-01,  1.0313e+00,\n",
      "           6.2975e-01,  3.5775e-01,  2.8952e-01, -3.4040e-01,  2.0904e+00,\n",
      "          -1.0000e+08],\n",
      "         [-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -2.0000e+08]],\n",
      "\n",
      "        [[ 1.0871e-01,  2.7952e-01,  1.7635e+00,  5.6416e-01,  5.8431e-03,\n",
      "           1.2305e+00, -6.1433e-01, -6.2579e-01, -2.0483e-02, -4.6495e-01,\n",
      "          -1.0000e+08],\n",
      "         [-7.8710e-01,  8.6694e-01,  2.7874e-01, -1.4588e+00,  5.4702e-02,\n",
      "          -3.9105e-01,  8.9033e-01,  4.9009e-01,  9.8705e-02,  1.8824e+00,\n",
      "          -1.0000e+08],\n",
      "         [-1.0626e+00,  7.7517e-01,  1.6693e+00, -1.1462e+00, -7.7567e-01,\n",
      "           2.9047e-01,  1.5410e+00,  3.0078e-01, -3.6842e-01,  1.2813e-01,\n",
      "          -1.0000e+08],\n",
      "         [-1.6343e-01, -4.5680e-01, -6.3909e-01, -1.3950e-01,  2.4925e-01,\n",
      "          -2.4321e-03, -5.6720e-01, -8.8464e-01, -6.1672e-01, -1.2580e+00,\n",
      "          -1.0000e+08],\n",
      "         [-1.5102e-01, -2.3638e-01, -1.0401e+00,  7.2062e-01, -1.6347e-01,\n",
      "          -1.4304e+00,  1.7046e+00, -3.5411e-01,  7.2751e-01,  1.0953e+00,\n",
      "          -1.0000e+08],\n",
      "         [-7.3963e-01, -9.3602e-02, -9.2488e-01, -8.0839e-01, -3.2466e-01,\n",
      "           4.8066e-01,  3.4536e-01,  1.5819e-01,  1.0314e+00, -4.2458e-02,\n",
      "          -1.0000e+08],\n",
      "         [ 4.6180e-01,  6.4232e-01, -5.5925e-01, -5.0015e-02,  8.1609e-01,\n",
      "           2.2447e-01,  1.7295e+00,  1.0687e+00,  6.3636e-01, -5.0780e-01,\n",
      "          -1.0000e+08],\n",
      "         [-8.1686e-01, -6.4404e-01,  1.4140e+00, -1.8898e+00, -3.4447e-01,\n",
      "           8.9468e-01,  2.1425e-01,  4.4432e-01,  7.6776e-01, -5.3645e-01,\n",
      "          -1.0000e+08],\n",
      "         [-9.3217e-01, -1.8497e-02,  1.0658e+00,  3.6539e-01,  1.0118e+00,\n",
      "           7.9211e-01,  1.7114e-01, -1.7501e+00, -6.1379e-01, -7.7250e-01,\n",
      "          -1.0000e+08],\n",
      "         [-5.0435e-01,  9.3028e-01,  2.5803e-01,  1.6756e-01,  4.7746e-01,\n",
      "           7.7321e-01, -1.1363e+00, -9.1338e-01, -6.8551e-01,  1.4998e-01,\n",
      "          -1.0000e+08],\n",
      "         [-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -2.0000e+08]],\n",
      "\n",
      "        [[-4.5537e-01, -1.2566e+00,  1.4479e+00, -1.4813e+00, -1.1770e+00,\n",
      "           1.0420e+00, -2.5060e-01,  1.4924e+00, -1.5341e+00, -5.1038e-01,\n",
      "          -1.0000e+08],\n",
      "         [-2.0571e-02, -1.1269e+00, -5.6797e-01, -3.5509e-01,  9.9108e-01,\n",
      "          -9.2670e-01, -1.5052e-01,  1.5954e+00, -2.4166e-01, -1.1794e+00,\n",
      "          -1.0000e+08],\n",
      "         [-5.3972e-01,  2.1648e+00,  1.0947e+00,  2.0992e-01,  1.0105e+00,\n",
      "           1.9301e-01,  5.2334e-01, -1.4063e-01, -9.1141e-01,  9.2613e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 1.0533e+00, -1.4137e+00,  1.0931e+00,  1.3018e+00,  1.2092e-01,\n",
      "          -2.0862e-01,  4.7123e-01, -1.9379e-01,  1.0685e+00,  1.6533e-01,\n",
      "          -1.0000e+08],\n",
      "         [-7.0628e-01, -1.5498e+00, -1.8773e+00,  8.1737e-01, -2.1485e+00,\n",
      "           1.8885e+00, -5.6085e-01, -4.6964e-01, -1.1633e-01,  1.8034e+00,\n",
      "          -1.0000e+08],\n",
      "         [-5.3152e-01,  1.5569e+00, -8.7097e-01,  1.7899e+00, -1.1912e+00,\n",
      "          -7.2379e-01, -6.0369e-01,  1.3037e+00, -7.4123e-01, -7.0488e-01,\n",
      "          -1.0000e+08],\n",
      "         [-3.1768e-01,  8.0070e-01,  1.0197e+00, -1.3190e-01, -9.5549e-01,\n",
      "           1.1795e+00, -4.6479e-01, -2.9195e-01, -6.4633e-01, -1.7569e+00,\n",
      "          -1.0000e+08],\n",
      "         [-2.6076e-01,  1.1965e-01,  1.5680e+00,  1.6040e-01,  6.4690e-01,\n",
      "           7.2718e-01, -1.1476e+00,  6.6797e-01,  2.3430e-03, -5.4070e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 1.1671e+00, -3.9987e-01, -1.9008e-01,  1.6973e+00,  9.7039e-01,\n",
      "           5.6149e-01, -4.7124e-01,  1.2055e+00,  1.1968e+00,  1.5100e+00,\n",
      "          -1.0000e+08],\n",
      "         [ 1.8685e+00,  4.9056e-01, -1.3559e+00, -1.3839e-01, -1.3964e+00,\n",
      "          -5.4609e-01, -9.8165e-01,  5.6158e-01, -1.9001e+00, -1.1090e+00,\n",
      "          -1.0000e+08],\n",
      "         [-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -2.0000e+08]],\n",
      "\n",
      "        [[-1.0950e+00, -3.0762e+00,  9.1229e-01,  3.8455e-01,  2.5701e-01,\n",
      "           7.9110e-01,  5.7016e-01,  8.1079e-01, -1.3280e-02,  8.8295e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 1.9105e-01, -5.3701e-01,  1.5074e+00, -8.8040e-01,  2.7199e-02,\n",
      "           1.4682e+00,  7.3866e-01,  1.2402e+00,  5.2677e-02,  2.4508e-01,\n",
      "          -1.0000e+08],\n",
      "         [-8.2665e-01,  8.1436e-01, -1.5395e+00,  5.4539e-01,  9.9772e-01,\n",
      "          -2.9221e-01,  6.5085e-02, -1.4083e+00,  8.7026e-01, -1.1413e+00,\n",
      "          -1.0000e+08],\n",
      "         [-8.4143e-01,  5.4913e-01, -5.8607e-02,  2.6967e-01,  8.4681e-02,\n",
      "           3.1634e-01, -1.3765e-01,  1.2593e+00, -3.6043e-01,  1.5472e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 8.9309e-01, -5.0531e-01,  8.6123e-01,  6.1226e-01,  6.0120e-01,\n",
      "          -5.9298e-01, -1.0930e+00, -9.1665e-01,  1.4710e+00,  1.4639e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 4.0225e-01, -1.6845e-01,  6.7015e-02,  1.5354e+00,  6.8751e-02,\n",
      "           9.5957e-01,  4.6851e-02, -9.0268e-01, -5.3035e-01,  1.4555e+00,\n",
      "          -1.0000e+08],\n",
      "         [ 1.6444e-01,  8.9052e-01,  7.6449e-01, -7.8986e-01, -6.0202e-02,\n",
      "          -1.1368e+00, -4.1138e-01,  6.8850e-01,  4.4923e-01, -4.9841e-02,\n",
      "          -1.0000e+08],\n",
      "         [-5.2292e-01,  4.2523e-01,  5.1964e-01, -4.8753e-01,  5.3084e-01,\n",
      "           1.9917e+00, -2.5837e-01, -3.4599e-01,  4.5572e-01, -3.8770e-01,\n",
      "          -1.0000e+08],\n",
      "         [ 1.0253e-01,  1.7645e+00, -1.0996e+00, -7.3824e-01, -1.7931e-01,\n",
      "           1.2732e-01, -8.9078e-03, -2.1203e+00, -6.7686e-01, -1.8467e+00,\n",
      "          -1.0000e+08],\n",
      "         [-1.2552e-01, -5.4513e-01, -7.4059e-01, -2.4909e-01,  1.4196e+00,\n",
      "           1.0743e+00,  2.2181e+00,  4.2201e-01, -1.1918e+00, -3.9275e-01,\n",
      "          -1.0000e+08],\n",
      "         [-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "          -2.0000e+08]]])\n"
     ]
    }
   ],
   "source": [
    "attended_arcs = attended_arcs + minus_mask.unsqueeze(2) + minus_mask.unsqueeze(1)\n",
    "print(attended_arcs.shape)\n",
    "print(attended_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head indices tensor([[7, 3, 7, 7, 7, 7, 0, 9, 7, 7],\n",
    "        [2, 0, 5, 5, 2, 8, 8, 5, 2, 0],\n",
    "        [3, 1, 4, 0, 4, 8, 8, 4, 4, 0],\n",
    "        [3, 3, 4, 0, 6, 4, 9, 9, 6, 4],\n",
    "        [2, 0, 6, 6, 6, 2, 8, 6, 2, 0],\n",
    "        [2, 0, 2, 3, 6, 2, 9, 9, 6, 2],\n",
    "        [3, 3, 0, 7, 7, 7, 3, 7, 3, 0],\n",
    "        [4, 4, 4, 8, 3, 7, 8, 0, 8, 0],\n",
    "        [3, 3, 6, 6, 6, 0, 9, 9, 6, 6],\n",
    "        [4, 4, 4, 0, 6, 4, 8, 4, 4, 0],\n",
    "        [5, 5, 5, 5, 0, 8, 8, 5, 5, 0],\n",
    "        [2, 0, 5, 5, 2, 9, 9, 9, 2, 2],\n",
    "        [2, 3, 0, 6, 6, 3, 9, 9, 3, 3],\n",
    "        [3, 3, 0, 3, 8, 8, 3, 7, 3, 0],\n",
    "        [6, 1, 6, 6, 6, 0, 9, 9, 6, 6],\n",
    "        [3, 3, 0, 3, 6, 4, 8, 6, 3, 0],\n",
    "        [6, 6, 4, 6, 6, 0, 9, 9, 6, 6],\n",
    "        [2, 0, 2, 6, 6, 2, 6, 9, 6, 2],\n",
    "        [5, 5, 5, 5, 0, 7, 5, 5, 5, 0],\n",
    "        [2, 4, 4, 0, 4, 9, 9, 5, 8, 4],\n",
    "        [2, 0, 4, 2, 4, 4, 2, 2, 2, 0],\n",
    "        [2, 0, 4, 2, 7, 7, 2, 9, 7, 2],\n",
    "        [4, 4, 4, 0, 4, 4, 8, 4, 4, 0],\n",
    "        [3, 3, 5, 5, 0, 7, 5, 9, 7, 5],\n",
    "        [2, 8, 5, 5, 2, 8, 8, 0, 8, 0],\n",
    "        [2, 5, 5, 5, 0, 8, 6, 5, 5, 0],\n",
    "        [5, 5, 5, 5, 0, 7, 5, 7, 5, 5],\n",
    "        [7, 3, 7, 7, 7, 7, 0, 9, 7, 7],\n",
    "        [0, 4, 4, 1, 1, 1, 6, 9, 6, 1],\n",
    "        [4, 4, 4, 0, 8, 8, 8, 4, 4, 0],\n",
    "        [5, 5, 4, 5, 0, 8, 8, 5, 5, 0],\n",
    "        [4, 4, 4, 0, 4, 4, 4, 9, 4, 9]], device='cuda:0')\n",
    "\n",
    "\n",
    "mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4717, 0.7192, 0.6074],\n",
      "        [0.0790, 0.9294, 0.0374],\n",
      "        [0.1606, 0.2051, 0.0593],\n",
      "        [0.9422, 0.9595, 0.6442]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tensor([[0.4717, 0.7192, 0.6074, 0.0000],\n",
      "        [0.0790, 0.9294, 0.0374, 0.0000],\n",
      "        [0.1606, 0.2051, 0.0593, 0.0000],\n",
      "        [0.9422, 0.9595, 0.6442, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "#[head_indices.new_zeros(batch_size, 1)\n",
    "a = torch.rand(4,3)\n",
    "print(a)\n",
    "\n",
    "b = a.new_zeros(4,1)\n",
    "print(b)\n",
    "\n",
    "c = torch.cat((a,b), 1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        attended_arcs : ``torch.Tensor``, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate\n",
    "            a distribution over attachments of a given word to all other words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
